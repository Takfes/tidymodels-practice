---
title: "tidymodels-practice"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## TODO 
1. future_frame https://business-science.github.io/timetk/reference/index.html
2. recursive https://business-science.github.io/modeltime/reference/recursive.html
3. replace step_ma with step_slidify_augment()
4. time_series_cv instead of time_series_split
5. hyperparameters tuning - racing methods
6. workflow sets
7. stacking

Install Packages
```{r}
# remotes::install_github("bagasbgy/quantrecipes")
# remotes::install_github('curso-r/treesnip')
# install.packages('modeltime.ensemble')
# remotes::install_github('catboost/catboost',subdir='catboost/R-package')
```

Load packages
```{r}

library(pacman)
pacman::p_load(takmeR,tidyverse,tidymodels,skimr,lubridate,janitor,
               modeltime,timetk,quantrecipes,modeltime.ensemble,
               treesnip,xgboost,lightgbm,randomForest,
               RSQLite,DBI,dbplyr,plotly,assertthat,
               xgboost,lightgbm)


```



Load Data
```{r}
con <-
  dbConnect(RSQLite::SQLite(),
            "/Users/takis/Documents/sckool/my-crypto-app/data/assets.db")

# # DBI
# dbListTables(con)
# dbListFields(con, "futures15")

res <-
  dbSendQuery(con, "SELECT * FROM futures15 where symbol = 'BTCUSDT'")
raw <- dbFetch(res)

raw %>% dim()

```


Dplyr Preprocessing (avoid this - prefer recipes)
```{r}

# df <- raw %>%  
#   arrange(openTime) %>% 
#   mutate(
#     openTime = as.POSIXct(openTime, format="%Y-%m-%d %H:%M:%S", tz="UTC"),
#     closeTime = as.POSIXct(closeTime, format="%Y-%m-%d %H:%M:%S", tz="UTC"),
#     close = lag(close,1,align='right'),
#     volume = lag(volume,1,align='right')
#     ) %>% 
#   select(time = openTime, close, volume) %>% 
#   tk_augment_lags(.value = c(close,volume), 
#                   .lags = c(1,4,8,16,96),
#                   .names = 'auto') %>% 
#   tk_augment_slidify(.value = ends_with('_lag1'), 
#                      .period  = c(24,48,96), 
#                      .f = 'mean') %>% 
#   tk_augment_timeseries_signature(time) %>% 
#   select(starts_with(c('time','close','volume')),
#          index.num,wday,month,am.pm,mday,yday,week) %>% 
#   janitor::clean_names() %>% 
#   na.omit()
#   
# nrow(raw) - nrow(df)
#   
# df %>% glimpse()
# df %>% isna()
# df %>% skim()

```

Train Test Split
```{r}

df <- raw %>%
  arrange(openTime) %>%
  mutate(
    openTime = as.POSIXct(openTime, format = "%Y-%m-%d %H:%M:%S", tz = "UTC"),
    closeTime = as.POSIXct(closeTime, format = "%Y-%m-%d %H:%M:%S", tz =
                             "UTC"),
  ) %>%
  select(time = openTime, close, volume) %>% 
  filter(time >= '2021-01-01')

raw %>% nrow()
df %>% nrow()

splits <- time_series_split(df, time, assess = 4*24, cumulative = T)
train <- training(splits)
test <- testing(splits)

train %>% dim()
test %>% dim()

# splits_cv <-  time_series_cv(df, time, assess = 4*24, cumulative = T, skip = 4*24*7)# slice_limit = 8)
# splits_cv %>% dim()

```


Time Series plots
```{r}

# df %>%
#   plot_time_series(time,close,
#                    .interactive=TRUE)

train %>% mutate(type = 'train') %>%
  bind_rows(test %>% mutate(type = 'test')) %>%
  arrange(time) %>% 
  filter(time >= '2021-08-10') %>% 
  ggplot(aes(x = time, y = close, color = type)) +
  geom_line() +
  labs(x=NULL,y=NULL) +
  ggtitle('Example Train Test Split (zoomed in)')

# splits_cv %>% plot_time_series_cv_plan(
#   time,
#   close,
#   .facet_ncol = 1,
#   .line_alpha = 0.5,
#   .interactive = F
# )


```



Preprocessing with Recipes
```{r}

# step_slidify_augment
# step_ma

recipe_spec <- recipe(close ~ ., data = train) %>%
  step_lag(volume, close, lag = c(1, 4, 8, 16)) %>%
  step_slidify_augment(
    starts_with('lag_1_'),
    align = 'right',
    period = c(4, 12, 24),
    .f = ~ mean(.x, na.rm = T),
    prefix = "MA_"
  ) %>%
  step_fourier(time, period = c(4, 8), K = 3) %>%
  step_timeseries_signature(time) %>%
  step_rm(
    matches(
      "(.iso$)|(.xts$)|(_year$)|(_quarter$)|(_halfl$)|(.lbl$)|(^time_week)|(time_half)"
    )
  ) %>%
  step_rm(volume) %>%
  update_role(time, new_role = 'id') %>%
  step_nzv(all_numeric_predictors(),-all_outcomes()) %>%
  step_zv(all_numeric_predictors(),-all_outcomes()) %>%
  step_corr(all_numeric_predictors(), -all_outcomes(), threshold = 0.9) %>%
  step_impute_median(all_predictors()) %>% 
  step_naomit(all_predictors(), -all_outcomes())
  

recipe_spec
recipe_spec %>% prep() %>% juice() %>% glimpse()

test_data <- recipe_spec %>% prep() %>% bake(new_data = test)
test_data %>% nrow()
test %>% nrow()

```

Fit Machine Learning Models

1. GLMNET
```{r}

glm_spec <- linear_reg(mixture = 0.5, penalty = 0.01) %>% 
  set_engine('glmnet') %>% 
  set_mode('regression')

glm_wf <- workflow() %>% 
  add_model(lasso_spec) %>% 
  add_recipe(recipe_spec)

glm_fit <- glm_wf %>% fit(train)

```

2. RANDOM FOREST
```{r}

rf_spec <- rand_forest(trees = 100, min_n = 10) %>% 
  set_engine('randomForest') %>% 
  set_mode('regression')

rf_wf <- workflow() %>% 
  add_model(rf_spec) %>% 
  add_recipe(recipe_spec)

rf_fit <- rf_wf %>% fit(train)

```

3. LGBM
```{r}

lgbm_spec <- boost_tree(mode = 'regression') %>% 
  set_engine('lightgbm', objective = 'tweedie')

lgbm_wf <- workflow() %>% 
  add_model(lgbm_spec) %>% 
  add_recipe(recipe_spec)

lgbm_fit <- lgbm_wf %>% fit(train)

```

4. XGBOOST
```{r}

xgb_spec <- boost_tree(mode = 'regression') %>% 
  set_engine('xgboost', objective = 'reg:tweedie')

xgb_wf <- workflow() %>% 
  add_model(xgb_spec) %>% 
  add_recipe(recipe_spec)

xgb_fit <- xgb_wf %>% fit(train)

```


MODELTIME WORKFLOW
```{r}
model_time_table <- modeltime_table(
  glm_fit,
  rf_fit,
  lgbm_fit,
  xgb_fit
)

model_time_table

calibration_tbl <- model_time_table %>%
  modeltime_calibrate(new_data = test, quiet = F)

calibration_tbl %>%
    modeltime_accuracy()

gg <- calibration_tbl %>%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = df
    )

gg %>% plot_modeltime_forecast()

gg %>% select(.index,.model_desc,.value) %>% 
  pivot_wider(names_from = .model_desc, values_from = .value) %>% tail()

```









